{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using device: cpu\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/code\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# import gym\n",
    "# import recogym\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.backends.cudnn.benchmark = torch.cuda.is_available()\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_float32_matmul_precision(\"high\")  # TF32 = big speedup on Ada\n",
    "\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# implementing OPE of the IPWLearner using synthetic bandit data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import softmax\n",
    "import optuna\n",
    "# from memory_profiler import profile\n",
    "\n",
    "\n",
    "from estimators import (\n",
    "    DirectMethod as DM\n",
    ")\n",
    "\n",
    "from simulation_utils import (\n",
    "    eval_policy,\n",
    "    generate_dataset,\n",
    "    create_simulation_data_from_pi,\n",
    "    get_train_data,\n",
    "    get_opl_results_dict,\n",
    "    CustomCFDataset,\n",
    "    calc_reward,\n",
    "    get_weights_info\n",
    ")\n",
    "\n",
    "from models import (    \n",
    "    CFModel,\n",
    "    NeighborhoodModel,\n",
    "    BPRModel, \n",
    "    RegressionModel\n",
    ")\n",
    "\n",
    "from training_utils import (\n",
    "    train,\n",
    "    validation_loop, \n",
    "    cv_score_model\n",
    " )\n",
    "\n",
    "from custom_losses import (\n",
    "    SNDRPolicyLoss\n",
    "    )\n",
    "\n",
    "random_state=12345\n",
    "random_ = check_random_state(random_state)\n",
    "\n",
    "pd.options.display.float_format = '{:,.8f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_results(\n",
    "    our_x, \n",
    "    our_a, \n",
    "    emb_x, \n",
    "    emb_a, \n",
    "    original_x, \n",
    "    original_a, \n",
    "    dataset, \n",
    "    val_data, \n",
    "    original_policy_prob, \n",
    "    neighberhoodmodel, \n",
    "    regression_model, \n",
    "    dm\n",
    "):\n",
    "    policy = np.expand_dims(softmax(our_x @ our_a.T, axis=1), -1)\n",
    "    policy_reward = calc_reward(dataset, policy)\n",
    "    eval_metrics = eval_policy(neighberhoodmodel, val_data, original_policy_prob, policy)\n",
    "    action_diff_to_real = np.sqrt(np.mean((emb_a - our_a) ** 2))\n",
    "    action_delta = np.sqrt(np.mean((original_a - our_a) ** 2))\n",
    "    context_diff_to_real = np.sqrt(np.mean((emb_x - our_x) ** 2))\n",
    "    context_delta = np.sqrt(np.mean((original_x - our_x) ** 2))\n",
    "\n",
    "    row = np.concatenate([\n",
    "        np.atleast_1d(policy_reward),\n",
    "        np.atleast_1d(eval_metrics),\n",
    "        np.atleast_1d(action_diff_to_real),\n",
    "        np.atleast_1d(action_delta),\n",
    "        np.atleast_1d(context_diff_to_real),\n",
    "        np.atleast_1d(context_delta)\n",
    "    ])\n",
    "    reg_dm = dm.estimate_policy_value(policy[val_data['x_idx']], regression_model.predict(val_data['x']))\n",
    "    reg_results = np.array([reg_dm])\n",
    "    conv_results = np.array([row])\n",
    "    return get_opl_results_dict(reg_results, conv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `trainer_trial` Function\n",
    "\n",
    "This function runs policy learning experiments using offline bandit data and evaluates various estimators.\n",
    "\n",
    "### Parameters\n",
    "- **num_runs** (int): Number of experimental runs per training size\n",
    "- **num_neighbors** (int): Number of neighbors to consider in the neighborhood model\n",
    "- **num_rounds_list** (list): List of training set sizes to evaluate\n",
    "- **dataset** (dict): Contains dataset information including embeddings, action probabilities, and reward probabilities\n",
    "- **batch_size** (int): Batch size for training the policy model\n",
    "- **num_epochs** (int): Number of training epochs for each experiment\n",
    "- **lr** (float, default=0.001): Learning rate for the optimizer\n",
    "\n",
    "### Process Flow\n",
    "1. Initializes result structures and retrieval models\n",
    "2. For each training size in `num_rounds_list`:\n",
    "   - Creates a uniform logging policy and simulates data\n",
    "   - Generates training data for offline learning\n",
    "   - Fits regression and neighborhood models for reward estimation\n",
    "   - Initializes and trains a counterfactual policy model\n",
    "   - Evaluates policy performance using various estimators\n",
    "   - Collects metrics on policy reward and embedding quality\n",
    "\n",
    "### Returns\n",
    "- **DataFrame**: Results table with rows indexed by training size and columns for various metrics:\n",
    "  - `policy_rewards`: True expected reward of the learned policy\n",
    "  - Various estimator errors (`ipw`, `reg_dm`, `conv_dm`, `conv_dr`, `conv_sndr`)\n",
    "  - Variance metrics for each estimator\n",
    "  - Embedding quality metrics comparing learned representations to ground truth\n",
    "\n",
    "### Implementation Notes\n",
    "- Uses uniform random logging policy for collecting offline data\n",
    "- Employs Self-Normalized Doubly Robust (SNDR) policy learning\n",
    "- Measures embedding quality via RMSE to original/ground truth embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_trial(\n",
    "    num_runs,\n",
    "    num_neighbors,\n",
    "    num_rounds_list,\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    val_size=2000,\n",
    "    n_trials=10,    \n",
    "    prev_best_params=None\n",
    "):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = torch.cuda.is_available()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    dm = DM()\n",
    "    results = {}\n",
    "\n",
    "    our_x, our_a = dataset[\"our_x\"], dataset[\"our_a\"]\n",
    "    emb_x, emb_a = dataset[\"emb_x\"], dataset[\"emb_a\"]\n",
    "\n",
    "    original_x, original_a = dataset[\"original_x\"], dataset[\"original_a\"]\n",
    "    n_users, n_actions, emb_dim = dataset[\"n_users\"], dataset[\"n_actions\"], dataset[\"emb_dim\"]\n",
    "\n",
    "    all_user_indices = np.arange(n_users, dtype=np.int64)\n",
    "\n",
    "    def T(x):\n",
    "        return torch.as_tensor(x, device=device, dtype=torch.float32)\n",
    "\n",
    "    def _mean_dict(dicts):\n",
    "        \"\"\"\n",
    "        Robust mean over a list of dicts with numeric/scalar/1D-array values.\n",
    "        Returns a single dict with elementwise means.\n",
    "        \"\"\"\n",
    "        if not dicts:\n",
    "            return {}\n",
    "        keys = dicts[0].keys()\n",
    "        out = {}\n",
    "        for k in keys:\n",
    "            vals = [d[k] for d in dicts if k in d]\n",
    "            # try to convert each to np.array and average\n",
    "            arrs = [np.asarray(v) for v in vals]\n",
    "            # broadcast to same shape if scalars/1D\n",
    "            stacked = np.stack(arrs, axis=0)\n",
    "            out[k] = np.mean(stacked, axis=0)\n",
    "        return out\n",
    "\n",
    "    # ===== unpack dataset (keep originals safe) =====\n",
    "    our_x_orig, our_a_orig = our_x, our_a\n",
    "    emb_x, emb_a = emb_x, emb_a\n",
    "    original_x, original_a = original_x, original_a\n",
    "    n_users, n_actions, emb_dim = n_users, n_actions, emb_dim\n",
    "    all_user_indices = np.arange(n_users, dtype=np.int64)\n",
    "\n",
    "    dm = DM()\n",
    "    results = {}\n",
    "    best_hyperparams_by_size = {}\n",
    "    last_best_params = prev_best_params if prev_best_params is not None else None\n",
    "\n",
    "    # ===== baseline (sample size = 0) using get_trial_results =====\n",
    "    pi_0 = softmax(our_x_orig @ our_a_orig.T, axis=1)\n",
    "    original_policy_prob = np.expand_dims(pi_0, -1)\n",
    "\n",
    "    simulation_data = create_simulation_data_from_pi(\n",
    "        dataset, pi_0, val_size, random_state=0\n",
    "    )\n",
    "\n",
    "    # use same data for train/val just to generate the baseline row\n",
    "    train_data = get_train_data(n_actions, val_size, simulation_data, np.arange(val_size), our_x_orig)\n",
    "    val_data   = get_train_data(n_actions, val_size, simulation_data, np.arange(val_size), our_x_orig)\n",
    "\n",
    "    regression_model = RegressionModel(\n",
    "        n_actions=n_actions, action_context=our_x_orig,\n",
    "        base_model=LogisticRegression(random_state=12345)\n",
    "    )\n",
    "\n",
    "    regression_model.fit(train_data['x'], train_data['a'], train_data['r'])\n",
    "\n",
    "    neighberhoodmodel = NeighborhoodModel(\n",
    "        train_data['x_idx'], train_data['a'],\n",
    "        our_a_orig, our_x_orig, train_data['r'],\n",
    "        num_neighbors=num_neighbors\n",
    "    )\n",
    "\n",
    "    # baseline row produced via get_trial_results\n",
    "    results[0] = get_trial_results(\n",
    "        our_x_orig, our_a_orig, emb_x, emb_a, original_x, original_a,\n",
    "        dataset, val_data, original_policy_prob,\n",
    "        neighberhoodmodel, regression_model, dm\n",
    "    )\n",
    "\n",
    "    # ===== main loop over training sizes =====\n",
    "    for train_size in num_rounds_list:\n",
    "\n",
    "        # we’ll collect per-run trial dicts generated by get_trial_results\n",
    "        trial_dicts_this_size = []\n",
    "        best_hyperparams_by_size[train_size] = {}\n",
    "\n",
    "        # --- prepare a resampling for Optuna’s objective (shared loaders built per-run inside objective) ---\n",
    "        # We’ll do Optuna per-run (fresh resample + search), then final fit with best params, then get_trial_results.\n",
    "\n",
    "        for run in range(num_runs):\n",
    "\n",
    "            # --- resample for this run ---\n",
    "            pi_0 = softmax(our_x_orig @ our_a_orig.T, axis=1)\n",
    "            original_policy_prob = np.expand_dims(pi_0, -1)\n",
    "\n",
    "            simulation_data = create_simulation_data_from_pi(\n",
    "                dataset, pi_0, train_size + val_size,\n",
    "                random_state=(run + 1) * (train_size + 17)\n",
    "            )\n",
    "\n",
    "            idx_train = np.arange(train_size)\n",
    "            train_data = get_train_data(n_actions, train_size, simulation_data, idx_train, our_x_orig)\n",
    "            val_idx   = np.arange(val_size) + train_size\n",
    "            val_data  = get_train_data(n_actions, val_size, simulation_data, val_idx, our_x_orig)\n",
    "\n",
    "            num_workers = 4 if torch.cuda.is_available() else 0\n",
    "\n",
    "            cf_dataset = CustomCFDataset(\n",
    "                train_data['x_idx'], train_data['a'], train_data['r'], original_policy_prob\n",
    "            )\n",
    "\n",
    "            val_dataset = CustomCFDataset(\n",
    "                val_data['x_idx'], val_data['a'], val_data['r'], original_policy_prob\n",
    "            )\n",
    "\n",
    "            # val_loader = DataLoader(\n",
    "            #     val_dataset, batch_size=val_size, shuffle=False,\n",
    "            #     pin_memory=torch.cuda.is_available(),\n",
    "            #     num_workers=num_workers, persistent_workers=bool(num_workers)\n",
    "            # )\n",
    "\n",
    "\n",
    "            # --- Optuna objective bound to this run's data ---\n",
    "            def objective(trial):\n",
    "                lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "                epochs = trial.suggest_int(\"num_epochs\", 1, 10)\n",
    "                trial_batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "                trial_num_neighbors = trial.suggest_int(\"num_neighbors\", 3, 15)\n",
    "                lr_decay = trial.suggest_float(\"lr_decay\", 0.8, 1.0)\n",
    "\n",
    "                trial_neigh_model = NeighborhoodModel(\n",
    "                    train_data['x_idx'], train_data['a'],\n",
    "                    our_a_orig, our_x_orig, train_data['r'],\n",
    "                    num_neighbors=trial_num_neighbors\n",
    "                )\n",
    "\n",
    "                trial_scores_all = torch.as_tensor(\n",
    "                    trial_neigh_model.predict(all_user_indices),\n",
    "                    device=device, dtype=torch.float32\n",
    "                )\n",
    "\n",
    "                trial_model = CFModel(\n",
    "                    n_users, n_actions, emb_dim,\n",
    "                    initial_user_embeddings=T(our_x_orig),\n",
    "                    initial_actions_embeddings=T(our_a_orig)\n",
    "                ).to(device)\n",
    "\n",
    "                assert (not torch.cuda.is_available()) or next(trial_model.parameters()).is_cuda\n",
    "\n",
    "                final_train_loader = DataLoader(\n",
    "                    cf_dataset, batch_size=trial_batch_size, shuffle=True,\n",
    "                    pin_memory=torch.cuda.is_available(),\n",
    "                    num_workers=num_workers, persistent_workers=bool(num_workers)\n",
    "                )\n",
    "\n",
    "                current_lr = lr\n",
    "                for epoch in range(epochs):\n",
    "                    if epoch > 0:\n",
    "                        current_lr *= lr_decay\n",
    "                        \n",
    "                    train(\n",
    "                        trial_model, final_train_loader, trial_scores_all,\n",
    "                        criterion=SNDRPolicyLoss(), num_epochs=1, lr=current_lr, device=str(device)\n",
    "                    )\n",
    "\n",
    "                trial_x, trial_a = trial_model.get_params()\n",
    "                trial_x = trial_x.detach().cpu().numpy()\n",
    "                trial_a = trial_a.detach().cpu().numpy()\n",
    "\n",
    "                pi_i = softmax(trial_x @ trial_a.T, axis=1)\n",
    "\n",
    "                print(get_weights_info(pi_i, original_policy_prob))\n",
    "                # validation reward for selection\n",
    "                return cv_score_model(val_data, trial_scores_all, pi_i)\n",
    "\n",
    "\n",
    "            # --- run Optuna for this run ---\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            \n",
    "            if last_best_params is not None:\n",
    "                study.enqueue_trial(last_best_params)\n",
    "\n",
    "            study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "            best_params = study.best_params\n",
    "            last_best_params = best_params  # optional warm-start to next run\n",
    "            best_hyperparams_by_size[train_size][run] = {\n",
    "                \"params\": best_params,\n",
    "                \"reward\": study.best_value\n",
    "            }\n",
    "\n",
    "\n",
    "            # --- final training with best params on this run’s data ---\n",
    "            regression_model = RegressionModel(\n",
    "                n_actions=n_actions, action_context=our_x_orig,\n",
    "                base_model=LogisticRegression(random_state=12345)\n",
    "            )\n",
    "            regression_model.fit(\n",
    "                train_data['x'], train_data['a'], train_data['r'],\n",
    "                original_policy_prob[train_data['x_idx'], train_data['a']].squeeze()\n",
    "            )\n",
    "\n",
    "            neighberhoodmodel = NeighborhoodModel(\n",
    "                train_data['x_idx'], train_data['a'],\n",
    "                our_a_orig, our_x_orig, train_data['r'],\n",
    "                num_neighbors=best_params['num_neighbors']\n",
    "            )\n",
    "            scores_all = torch.as_tensor(\n",
    "                neighberhoodmodel.predict(all_user_indices),\n",
    "                device=device, dtype=torch.float32\n",
    "            )\n",
    "\n",
    "            model = CFModel(\n",
    "                n_users, n_actions, emb_dim,\n",
    "                initial_user_embeddings=T(our_x_orig),\n",
    "                initial_actions_embeddings=T(our_a_orig)\n",
    "            ).to(device)\n",
    "            assert (not torch.cuda.is_available()) or next(model.parameters()).is_cuda\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                cf_dataset, batch_size=batch_size, shuffle=True,\n",
    "                pin_memory=torch.cuda.is_available(),\n",
    "                num_workers=num_workers, persistent_workers=bool(num_workers)\n",
    "            )\n",
    "\n",
    "            current_lr = best_params['lr']\n",
    "            for epoch in range(best_params['num_epochs']):\n",
    "                if epoch > 0:\n",
    "                    current_lr *= best_params['lr_decay']\n",
    "                train(\n",
    "                    model, train_loader, scores_all,\n",
    "                    criterion=SNDRPolicyLoss(), num_epochs=1, lr=current_lr, device=str(device)\n",
    "                )\n",
    "\n",
    "            # learned embeddings (do NOT overwrite originals)\n",
    "            learned_x_t, learned_a_t = model.get_params()\n",
    "            learned_x = learned_x_t.detach().cpu().numpy()\n",
    "            learned_a = learned_a_t.detach().cpu().numpy()\n",
    "\n",
    "            # --- produce the per-run result via get_trial_results ---\n",
    "            trial_res = get_trial_results(\n",
    "                learned_x, learned_a,          # learned (policy) embeddings\n",
    "                emb_x, emb_a,                  # ground-truth embedding refs\n",
    "                original_x, original_a,        # original clean refs\n",
    "                dataset,\n",
    "                val_data,                      # use this run's val split\n",
    "                original_policy_prob,\n",
    "                neighberhoodmodel,\n",
    "                regression_model,\n",
    "                dm\n",
    "            )\n",
    "\n",
    "            trial_dicts_this_size.append(trial_res)\n",
    "\n",
    "            # memory hygiene\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # === aggregate per-run results (mean) and store under this train_size ===\n",
    "        results[train_size] = _mean_dict(trial_dicts_this_size)\n",
    "\n",
    "    return pd.DataFrame.from_dict(results, orient='index'), best_hyperparams_by_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run several simulations on a generated dataset, the dataset is generated like this:\n",
    "$$ \\text{We have users U and actions A } u_i \\sim N(0, I_{emb_dim}) \\ a_i \\sim N(0, I_{emb_dim})$$\n",
    "$$ p_{ij} = 1 / (5 + e^{-(u_i.T a_j)}) $$\n",
    "$$r_{ij} \\sim Bin(p_{ij})$$\n",
    "\n",
    "We have a policy $\\pi$\n",
    "and it's ground truth reward is calculated by\n",
    "$$R_{gt} = \\sum_{i}{\\sum_{j}{\\pi_{ij} * p_{ij}}} $$\n",
    "\n",
    "Our parameters for the dataset will be\n",
    "$$EmbDim = 5$$\n",
    "$$NumActions= 150$$\n",
    "$$NumUsers = 150$$\n",
    "$$NeighborhoodSize = 6$$\n",
    "\n",
    "to learn a new policy from $\\pi$ we will sample from:\n",
    "$$\\pi_{start} = (1-\\epsilon)*\\pi + \\epsilon * \\pi_{random}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Item CTR: 0.07066414727263938\n",
      "Optimal greedy CTR: 0.09999926940951757\n",
      "Optimal Stochastic CTR: 0.09995326955796031\n",
      "Our Initial CTR: 0.08610747363354625\n"
     ]
    }
   ],
   "source": [
    "dataset_params = dict(\n",
    "                    n_actions= 500,\n",
    "                    n_users = 500,\n",
    "                    emb_dim = 16,\n",
    "                    # sigma = 0.1,\n",
    "                    eps = 0.6, # this is the epsilon for the noise in the ground truth policy representation\n",
    "                    ctr = 0.1\n",
    "                    )\n",
    "\n",
    "train_dataset = generate_dataset(dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 1\n",
    "batch_size = 200\n",
    "num_neighbors = 6\n",
    "n_trials_for_optuna = 50\n",
    "num_rounds_list = [500, 1000, 2000, 10000, 20000]\n",
    "# num_rounds_list = [20000]\n",
    "\n",
    "\n",
    "# Manually define your best parameters\n",
    "best_params_to_use = {\n",
    "    \"lr\": 0.0095,  # Learning rate\n",
    "    \"num_epochs\": 5,  # Number of training epochs\n",
    "    \"batch_size\": 64,  # Batch size for training\n",
    "    \"num_neighbors\": 8,  # Number of neighbors for neighborhood model\n",
    "    \"lr_decay\": 0.85  # Learning rate decay factor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "\n",
    "$$emb = 0.7 * gt + 0.3 * noise$$\n",
    "$$lr = 0.005$$\n",
    "$$n_{epochs} = 1$$\n",
    "$$BatchSize=50$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of num_rounds_list: [500, 1000, 2000, 10000, 20000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 15:30:21,228] A new study created in memory with name: no-name-b1c182ce-86bb-4c4a-a476-5a162cf51afe\n",
      "Best trial: 0. Best value: -0.00865103:   2%|▏         | 1/50 [00:02<01:52,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.40408135351240027), 'ess': np.float64(165822.8754548929), 'max_wi': np.float64(6.6850931907224105), 'min_wi': np.float64(0.012997558145085754)}\n",
      "[I 2025-10-01 15:30:23,516] Trial 0 finished with value: -0.008651025705584873 and parameters: {'lr': 0.0095, 'num_epochs': 5, 'batch_size': 64, 'num_neighbors': 8, 'lr_decay': 0.85}. Best is trial 0 with value: -0.008651025705584873.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: -0.00830631:   4%|▍         | 2/50 [00:03<01:30,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.009550868274245028), 'ess': np.float64(249928.04691040178), 'max_wi': np.float64(1.0463413835121627), 'min_wi': np.float64(0.9432234036870707)}\n",
      "[I 2025-10-01 15:30:25,107] Trial 1 finished with value: -0.008306305473049015 and parameters: {'lr': 0.0003492101076594037, 'num_epochs': 3, 'batch_size': 128, 'num_neighbors': 13, 'lr_decay': 0.9921847299109916}. Best is trial 1 with value: -0.008306305473049015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: -0.00830631:   6%|▌         | 3/50 [00:05<01:22,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.2810461598458946), 'ess': np.float64(201431.56187775044), 'max_wi': np.float64(3.9347998970584532), 'min_wi': np.float64(0.10695843642185762)}\n",
      "[I 2025-10-01 15:30:26,701] Trial 2 finished with value: -0.008778997760828673 and parameters: {'lr': 0.0047237651051862724, 'num_epochs': 5, 'batch_size': 64, 'num_neighbors': 6, 'lr_decay': 0.9371375875369643}. Best is trial 1 with value: -0.008306305473049015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: -0.00830631:   8%|▊         | 4/50 [00:07<01:18,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.06190253595218667), 'ess': np.float64(247069.20919380258), 'max_wi': np.float64(1.370503699137448), 'min_wi': np.float64(0.6860749619442146)}\n",
      "[I 2025-10-01 15:30:28,365] Trial 3 finished with value: -0.008335498572771723 and parameters: {'lr': 0.0014021547187254787, 'num_epochs': 3, 'batch_size': 64, 'num_neighbors': 13, 'lr_decay': 0.941410494998372}. Best is trial 1 with value: -0.008306305473049015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: -0.00830631:  10%|█         | 5/50 [00:08<01:15,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0015992662699963812), 'ess': np.float64(249997.90653245358), 'max_wi': np.float64(1.0065715454666753), 'min_wi': np.float64(0.9908295655828836)}\n",
      "[I 2025-10-01 15:30:29,976] Trial 4 finished with value: -0.008518659426660673 and parameters: {'lr': 0.00016373991494485015, 'num_epochs': 3, 'batch_size': 512, 'num_neighbors': 5, 'lr_decay': 0.9193414861989612}. Best is trial 1 with value: -0.008306305473049015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.00829023:  12%|█▏        | 6/50 [00:10<01:13,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.005977617056358519), 'ess': np.float64(249970.78120838874), 'max_wi': np.float64(1.0247484937912767), 'min_wi': np.float64(0.9660362403397448)}\n",
      "[I 2025-10-01 15:30:31,624] Trial 5 finished with value: -0.008290231227185519 and parameters: {'lr': 0.0003331166809194788, 'num_epochs': 8, 'batch_size': 512, 'num_neighbors': 12, 'lr_decay': 0.8649479272041829}. Best is trial 5 with value: -0.008290231227185519.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.00829023:  14%|█▍        | 7/50 [00:12<01:11,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.02475003206153017), 'ess': np.float64(249509.93225722923), 'max_wi': np.float64(1.127181546895956), 'min_wi': np.float64(0.8596019955465549)}\n",
      "[I 2025-10-01 15:30:33,247] Trial 6 finished with value: -0.008558195255526941 and parameters: {'lr': 0.0022681893135742498, 'num_epochs': 2, 'batch_size': 256, 'num_neighbors': 9, 'lr_decay': 0.9334097204313898}. Best is trial 5 with value: -0.008290231227185519.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.00829023:  16%|█▌        | 8/50 [00:13<01:08,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.055277421086979674), 'ess': np.float64(247548.1942747799), 'max_wi': np.float64(1.2523942165803776), 'min_wi': np.float64(0.715810741324646)}\n",
      "[I 2025-10-01 15:30:34,854] Trial 7 finished with value: -0.008856590173805664 and parameters: {'lr': 0.00448839124426945, 'num_epochs': 4, 'batch_size': 512, 'num_neighbors': 4, 'lr_decay': 0.9234970435509054}. Best is trial 5 with value: -0.008290231227185519.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.00829023:  18%|█▊        | 9/50 [00:15<01:07,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0037538981634174717), 'ess': np.float64(249988.81822557014), 'max_wi': np.float64(1.0174321268677016), 'min_wi': np.float64(0.9762503654451352)}\n",
      "[I 2025-10-01 15:30:36,553] Trial 8 finished with value: -0.008636533272981608 and parameters: {'lr': 0.00018959871817723908, 'num_epochs': 5, 'batch_size': 256, 'num_neighbors': 7, 'lr_decay': 0.8317327716404882}. Best is trial 5 with value: -0.008290231227185519.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: -0.008286:  20%|██        | 10/50 [00:16<01:05,  1.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0010629286237055131), 'ess': np.float64(249999.07505826798), 'max_wi': np.float64(1.0043615961686618), 'min_wi': np.float64(0.9939022972126248)}\n",
      "[I 2025-10-01 15:30:38,150] Trial 9 finished with value: -0.00828599628365239 and parameters: {'lr': 0.0001668903770927532, 'num_epochs': 2, 'batch_size': 512, 'num_neighbors': 12, 'lr_decay': 0.8012721736260111}. Best is trial 9 with value: -0.00828599628365239.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  22%|██▏       | 11/50 [00:18<01:03,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.005594980143018311), 'ess': np.float64(249974.36297044568), 'max_wi': np.float64(1.0277463457779874), 'min_wi': np.float64(0.9672636486212093)}\n",
      "[I 2025-10-01 15:30:39,747] Trial 10 finished with value: -0.00816584277780242 and parameters: {'lr': 0.0005792398201366767, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8039639225036387}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  24%|██▍       | 12/50 [00:20<01:02,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.006202463437346538), 'ess': np.float64(249968.2306582709), 'max_wi': np.float64(1.0285165801840424), 'min_wi': np.float64(0.962929551042903)}\n",
      "[I 2025-10-01 15:30:41,393] Trial 11 finished with value: -0.00817004123053909 and parameters: {'lr': 0.0006398264323558589, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.800664103939745}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  26%|██▌       | 13/50 [00:21<00:59,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0061298501510206075), 'ess': np.float64(249969.34097515236), 'max_wi': np.float64(1.0331520406663735), 'min_wi': np.float64(0.9602585664106824)}\n",
      "[I 2025-10-01 15:30:42,982] Trial 12 finished with value: -0.00816618809482683 and parameters: {'lr': 0.0006458520315022833, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8056473111442846}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  28%|██▊       | 14/50 [00:23<00:58,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.034623805462395546), 'ess': np.float64(249070.78106060752), 'max_wi': np.float64(1.1763716248400016), 'min_wi': np.float64(0.8229149838753685)}\n",
      "[I 2025-10-01 15:30:44,657] Trial 13 finished with value: -0.00819454581182358 and parameters: {'lr': 0.0006509515823268328, 'num_epochs': 10, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8749159012945495}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  30%|███       | 15/50 [00:24<00:56,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.009996888647664928), 'ess': np.float64(249917.77778081907), 'max_wi': np.float64(1.0458305289580163), 'min_wi': np.float64(0.9378057287179167)}\n",
      "[I 2025-10-01 15:30:46,213] Trial 14 finished with value: -0.00836972894483524 and parameters: {'lr': 0.0010408089986116318, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 11, 'lr_decay': 0.8267444366429995}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  32%|███▏      | 16/50 [00:26<00:55,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.01969213105903264), 'ess': np.float64(249698.02769229948), 'max_wi': np.float64(1.1003876076385366), 'min_wi': np.float64(0.8992017796381105)}\n",
      "[I 2025-10-01 15:30:47,927] Trial 15 finished with value: -0.00818003116536382 and parameters: {'lr': 0.0004354452209675935, 'num_epochs': 7, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8880745349794974}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  34%|███▍      | 17/50 [00:28<00:53,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.014209827792922783), 'ess': np.float64(249835.07531066993), 'max_wi': np.float64(1.0735016890895293), 'min_wi': np.float64(0.920294210978682)}\n",
      "[I 2025-10-01 15:30:49,512] Trial 16 finished with value: -0.008464224458048966 and parameters: {'lr': 0.0014754028668387085, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 10, 'lr_decay': 0.8246778163412122}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  36%|███▌      | 18/50 [00:29<00:52,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.02785700382289883), 'ess': np.float64(249399.61994466686), 'max_wi': np.float64(1.1450001988215035), 'min_wi': np.float64(0.8462493485625164)}\n",
      "[I 2025-10-01 15:30:51,189] Trial 17 finished with value: -0.00823103715380283 and parameters: {'lr': 0.0006896163959523733, 'num_epochs': 7, 'batch_size': 128, 'num_neighbors': 14, 'lr_decay': 0.8475497736685316}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  38%|███▊      | 19/50 [00:31<00:50,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.042131658188601165), 'ess': np.float64(248614.10853933543), 'max_wi': np.float64(1.2266531050411134), 'min_wi': np.float64(0.7711738017109608)}\n",
      "[I 2025-10-01 15:30:52,810] Trial 18 finished with value: -0.008316508234472414 and parameters: {'lr': 0.002270528661896805, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 13, 'lr_decay': 0.9855257156930795}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  40%|████      | 20/50 [00:33<00:49,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.010061339707137181), 'ess': np.float64(249920.32168922917), 'max_wi': np.float64(1.0495823821374328), 'min_wi': np.float64(0.9430310570230466)}\n",
      "[I 2025-10-01 15:30:54,513] Trial 19 finished with value: -0.008779924165966669 and parameters: {'lr': 0.0003859003043609369, 'num_epochs': 10, 'batch_size': 256, 'num_neighbors': 3, 'lr_decay': 0.814825254802979}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.00816584:  42%|████▏     | 21/50 [00:34<00:47,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0029339975805340755), 'ess': np.float64(249993.20783749), 'max_wi': np.float64(1.0155152554581597), 'min_wi': np.float64(0.9817160064843171)}\n",
      "[I 2025-10-01 15:30:56,119] Trial 20 finished with value: -0.008440352171747259 and parameters: {'lr': 0.0001016703297951095, 'num_epochs': 4, 'batch_size': 128, 'num_neighbors': 10, 'lr_decay': 0.8478713124950682}. Best is trial 10 with value: -0.00816584277780242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.00816457:  44%|████▍     | 22/50 [00:36<00:45,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.005869595849389141), 'ess': np.float64(249971.71425841484), 'max_wi': np.float64(1.0292353981244264), 'min_wi': np.float64(0.9634218891862482)}\n",
      "[I 2025-10-01 15:30:57,759] Trial 21 finished with value: -0.008164571851198362 and parameters: {'lr': 0.0006143330982197509, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8030689230667892}. Best is trial 21 with value: -0.008164571851198362.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.00816457:  46%|████▌     | 23/50 [00:38<00:43,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0076331538424940695), 'ess': np.float64(249952.07294241), 'max_wi': np.float64(1.0382223155633168), 'min_wi': np.float64(0.9518975833180364)}\n",
      "[I 2025-10-01 15:30:59,362] Trial 22 finished with value: -0.008225712331771134 and parameters: {'lr': 0.0007998474454784035, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 14, 'lr_decay': 0.8124345323974064}. Best is trial 21 with value: -0.008164571851198362.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.00816457:  48%|████▊     | 24/50 [00:39<00:42,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.007631147802518705), 'ess': np.float64(249953.50428509247), 'max_wi': np.float64(1.0404475123247392), 'min_wi': np.float64(0.9526614472634778)}\n",
      "[I 2025-10-01 15:31:01,008] Trial 23 finished with value: -0.008227319384124512 and parameters: {'lr': 0.00044898394497364986, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 14, 'lr_decay': 0.8329684620953282}. Best is trial 21 with value: -0.008164571851198362.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  50%|█████     | 25/50 [00:41<00:40,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0026736786360868608), 'ess': np.float64(249994.23400475175), 'max_wi': np.float64(1.0139387873247805), 'min_wi': np.float64(0.9849337146697912)}\n",
      "[I 2025-10-01 15:31:02,602] Trial 24 finished with value: -0.008164337950792359 and parameters: {'lr': 0.00027709918970579615, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8000161005043485}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  52%|█████▏    | 26/50 [00:42<00:38,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.005995031036930361), 'ess': np.float64(249971.680473601), 'max_wi': np.float64(1.0289311970078028), 'min_wi': np.float64(0.9661432746520132)}\n",
      "[I 2025-10-01 15:31:04,199] Trial 25 finished with value: -0.008285634426757697 and parameters: {'lr': 0.00025021842995115597, 'num_epochs': 3, 'batch_size': 128, 'num_neighbors': 12, 'lr_decay': 0.8646110743415786}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  54%|█████▍    | 27/50 [00:44<00:37,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.004095442599868318), 'ess': np.float64(249986.66026737317), 'max_wi': np.float64(1.021754177528384), 'min_wi': np.float64(0.9742975468588876)}\n",
      "[I 2025-10-01 15:31:05,814] Trial 26 finished with value: -0.008228850404085527 and parameters: {'lr': 0.00023512036921091421, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 14, 'lr_decay': 0.9002112685279765}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  56%|█████▌    | 28/50 [00:46<00:35,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.00506138035858204), 'ess': np.float64(249980.00000681012), 'max_wi': np.float64(1.0255970158530718), 'min_wi': np.float64(0.9696330478783677)}\n",
      "[I 2025-10-01 15:31:07,438] Trial 27 finished with value: -0.008366375977233408 and parameters: {'lr': 0.00010339796327409263, 'num_epochs': 4, 'batch_size': 64, 'num_neighbors': 11, 'lr_decay': 0.840351743294758}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  58%|█████▊    | 29/50 [00:47<00:34,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.005823242935283665), 'ess': np.float64(249972.27847087276), 'max_wi': np.float64(1.0276399355600159), 'min_wi': np.float64(0.9668908506645371)}\n",
      "[I 2025-10-01 15:31:09,088] Trial 28 finished with value: -0.008302946075710119 and parameters: {'lr': 0.0010059942742010294, 'num_epochs': 1, 'batch_size': 256, 'num_neighbors': 13, 'lr_decay': 0.8178045777900285}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  60%|██████    | 30/50 [00:49<00:32,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.03175385389776177), 'ess': np.float64(249222.2945567292), 'max_wi': np.float64(1.1654360104586208), 'min_wi': np.float64(0.8168240775681119)}\n",
      "[I 2025-10-01 15:31:10,746] Trial 29 finished with value: -0.008555820056530803 and parameters: {'lr': 0.00048016511727003684, 'num_epochs': 6, 'batch_size': 64, 'num_neighbors': 8, 'lr_decay': 0.8630264535942166}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  62%|██████▏   | 31/50 [00:51<00:31,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.004640100663551571), 'ess': np.float64(249982.80068978865), 'max_wi': np.float64(1.023946698873982), 'min_wi': np.float64(0.9730650147282662)}\n",
      "[I 2025-10-01 15:31:12,377] Trial 30 finished with value: -0.008165207588103417 and parameters: {'lr': 0.00027019017136917565, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8179847682596127}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  64%|██████▍   | 32/50 [00:52<00:29,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.004646215412601606), 'ess': np.float64(249982.83753827924), 'max_wi': np.float64(1.0227435032454135), 'min_wi': np.float64(0.9730633276843679)}\n",
      "[I 2025-10-01 15:31:13,990] Trial 31 finished with value: -0.008164397599625737 and parameters: {'lr': 0.0002729116364371551, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8191022692001436}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  66%|██████▌   | 33/50 [00:54<00:27,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.00445836720483108), 'ess': np.float64(249984.18877291176), 'max_wi': np.float64(1.0228772696167119), 'min_wi': np.float64(0.9743489739323542)}\n",
      "[I 2025-10-01 15:31:15,625] Trial 32 finished with value: -0.008229560711521975 and parameters: {'lr': 0.0002622980812989751, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 14, 'lr_decay': 0.8193397687231945}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  68%|██████▊   | 34/50 [00:56<00:26,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.008293241016751248), 'ess': np.float64(249945.527428984), 'max_wi': np.float64(1.0427682391708508), 'min_wi': np.float64(0.9501718170407719)}\n",
      "[I 2025-10-01 15:31:17,284] Trial 33 finished with value: -0.008300224324200882 and parameters: {'lr': 0.00030821251112823786, 'num_epochs': 3, 'batch_size': 128, 'num_neighbors': 13, 'lr_decay': 0.971158620384831}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  70%|███████   | 35/50 [00:57<00:24,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.004618786409293234), 'ess': np.float64(249983.11565123423), 'max_wi': np.float64(1.0222937560986158), 'min_wi': np.float64(0.9737249161903242)}\n",
      "[I 2025-10-01 15:31:18,918] Trial 34 finished with value: -0.008167010450457937 and parameters: {'lr': 0.00019931699876548723, 'num_epochs': 3, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8412907102556448}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  72%|███████▏  | 36/50 [00:59<00:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0038775105954834414), 'ess': np.float64(249988.0744289153), 'max_wi': np.float64(1.0194210342106358), 'min_wi': np.float64(0.9773922389060659)}\n",
      "[I 2025-10-01 15:31:20,577] Trial 35 finished with value: -0.00823050934806256 and parameters: {'lr': 0.00013355775878324557, 'num_epochs': 2, 'batch_size': 64, 'num_neighbors': 14, 'lr_decay': 0.8138164046421575}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  74%|███████▍  | 37/50 [01:01<00:21,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.008727242102061742), 'ess': np.float64(249940.2626282969), 'max_wi': np.float64(1.0429399921249338), 'min_wi': np.float64(0.9492184010948006)}\n",
      "[I 2025-10-01 15:31:22,228] Trial 36 finished with value: -0.008299910232517855 and parameters: {'lr': 0.00030658606559628185, 'num_epochs': 4, 'batch_size': 128, 'num_neighbors': 13, 'lr_decay': 0.8339830040065375}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  76%|███████▌  | 38/50 [01:02<00:19,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.08023364050295664), 'ess': np.float64(244911.13023472382), 'max_wi': np.float64(1.3865715383690926), 'min_wi': np.float64(0.6073666732857843)}\n",
      "[I 2025-10-01 15:31:23,874] Trial 37 finished with value: -0.008370164099193193 and parameters: {'lr': 0.009076145704900198, 'num_epochs': 3, 'batch_size': 512, 'num_neighbors': 12, 'lr_decay': 0.85756540247065}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  78%|███████▊  | 39/50 [01:04<00:18,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0027008881840663848), 'ess': np.float64(249994.21956188002), 'max_wi': np.float64(1.0130921557168173), 'min_wi': np.float64(0.985262770063087)}\n",
      "[I 2025-10-01 15:31:25,524] Trial 38 finished with value: -0.008166052897754227 and parameters: {'lr': 0.00014618622526002724, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.9576408583014726}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  80%|████████  | 40/50 [01:05<00:16,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.03040182655326042), 'ess': np.float64(249272.11783920226), 'max_wi': np.float64(1.1505856378075412), 'min_wi': np.float64(0.8206456137149871)}\n",
      "[I 2025-10-01 15:31:27,146] Trial 39 finished with value: -0.008642840647382135 and parameters: {'lr': 0.00135098348679697, 'num_epochs': 5, 'batch_size': 256, 'num_neighbors': 6, 'lr_decay': 0.8994321823300094}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  82%|████████▏ | 41/50 [01:07<00:14,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.006567427199942143), 'ess': np.float64(249964.73463439016), 'max_wi': np.float64(1.02722051756333), 'min_wi': np.float64(0.9627232588438793)}\n",
      "[I 2025-10-01 15:31:28,866] Trial 40 finished with value: -0.008233932056540052 and parameters: {'lr': 0.0003277334949651814, 'num_epochs': 9, 'batch_size': 512, 'num_neighbors': 14, 'lr_decay': 0.8792413267788508}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  84%|████████▍ | 42/50 [01:09<00:13,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.005535740141543364), 'ess': np.float64(249974.85991731213), 'max_wi': np.float64(1.0268330096594478), 'min_wi': np.float64(0.9692088494055054)}\n",
      "[I 2025-10-01 15:31:30,512] Trial 41 finished with value: -0.008172226027694516 and parameters: {'lr': 0.0005690189828640535, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8062001692152938}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  86%|████████▌ | 43/50 [01:10<00:11,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.001995700410191967), 'ess': np.float64(249996.740425026), 'max_wi': np.float64(1.0108344781883014), 'min_wi': np.float64(0.9872229957114854)}\n",
      "[I 2025-10-01 15:31:32,163] Trial 42 finished with value: -0.008164696771501783 and parameters: {'lr': 0.00020693132353647456, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8001221842123989}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: -0.00816434:  88%|████████▊ | 44/50 [01:12<00:09,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.001980209615031799), 'ess': np.float64(249996.79382723724), 'max_wi': np.float64(1.009484406209847), 'min_wi': np.float64(0.9870406558060784)}\n",
      "[I 2025-10-01 15:31:33,781] Trial 43 finished with value: -0.008227849238207867 and parameters: {'lr': 0.00020358971340340314, 'num_epochs': 1, 'batch_size': 128, 'num_neighbors': 14, 'lr_decay': 0.8232719978410347}. Best is trial 24 with value: -0.008164337950792359.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: -0.00816396:  90%|█████████ | 45/50 [01:14<00:08,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.002328613613675946), 'ess': np.float64(249995.68045209345), 'max_wi': np.float64(1.0117779719856053), 'min_wi': np.float64(0.9859739767974958)}\n",
      "[I 2025-10-01 15:31:35,407] Trial 44 finished with value: -0.008163962755856928 and parameters: {'lr': 0.0001381078986803915, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 15, 'lr_decay': 0.8000865035210912}. Best is trial 44 with value: -0.008163962755856928.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: -0.00816396:  92%|█████████▏| 46/50 [01:15<00:06,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.004032656968885356), 'ess': np.float64(249987.04820875294), 'max_wi': np.float64(1.0190700791345406), 'min_wi': np.float64(0.9753098315012226)}\n",
      "[I 2025-10-01 15:31:37,053] Trial 45 finished with value: -0.008302004997511166 and parameters: {'lr': 0.00018037092336658017, 'num_epochs': 3, 'batch_size': 128, 'num_neighbors': 13, 'lr_decay': 0.8026220729888982}. Best is trial 44 with value: -0.008163962755856928.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: -0.00816396:  94%|█████████▍| 47/50 [01:17<00:04,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0021053881208348275), 'ess': np.float64(249996.45147268358), 'max_wi': np.float64(1.0106291712764162), 'min_wi': np.float64(0.9885180431864301)}\n",
      "[I 2025-10-01 15:31:38,703] Trial 46 finished with value: -0.008165444549768947 and parameters: {'lr': 0.00012818206344151014, 'num_epochs': 1, 'batch_size': 64, 'num_neighbors': 15, 'lr_decay': 0.8001527909082651}. Best is trial 44 with value: -0.008163962755856928.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: -0.00816396:  96%|█████████▌| 48/50 [01:19<00:03,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0036982407184482547), 'ess': np.float64(249989.0734211782), 'max_wi': np.float64(1.0170454290007809), 'min_wi': np.float64(0.9756599704758526)}\n",
      "[I 2025-10-01 15:31:40,324] Trial 47 finished with value: -0.008305092562343807 and parameters: {'lr': 0.0002186617412429803, 'num_epochs': 2, 'batch_size': 128, 'num_neighbors': 13, 'lr_decay': 0.8121484791968973}. Best is trial 44 with value: -0.008163962755856928.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: -0.00816396:  98%|█████████▊| 49/50 [01:20<00:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0005511801316785044), 'ess': np.float64(249999.75125646926), 'max_wi': np.float64(1.0022596087464426), 'min_wi': np.float64(0.9968354385001351)}\n",
      "[I 2025-10-01 15:31:41,948] Trial 48 finished with value: -0.008228942765870665 and parameters: {'lr': 0.00015585418754553656, 'num_epochs': 1, 'batch_size': 512, 'num_neighbors': 14, 'lr_decay': 0.8285923176095564}. Best is trial 44 with value: -0.008163962755856928.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: -0.00816396: 100%|██████████| 50/50 [01:22<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gini': np.float64(0.0033157545906658324), 'ess': np.float64(249991.35517540027), 'max_wi': np.float64(1.0166187774335813), 'min_wi': np.float64(0.9808881408306281)}\n",
      "[I 2025-10-01 15:31:43,595] Trial 49 finished with value: -0.008286964862933495 and parameters: {'lr': 0.0001203393482579109, 'num_epochs': 4, 'batch_size': 128, 'num_neighbors': 12, 'lr_decay': 0.8110332356751904}. Best is trial 44 with value: -0.008163962755856928.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got multiple values for argument 'criterion'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mValue of num_rounds_list:\u001b[39m\u001b[33m\"\u001b[39m, num_rounds_list)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df4, best_hyperparams_by_size = \u001b[43mtrainer_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rounds_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials_for_optuna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_best_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_params_to_use\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Print best hyperparameters for each training size\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== BEST HYPERPARAMETERS BY TRAINING SIZE ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 243\u001b[39m, in \u001b[36mtrainer_trial\u001b[39m\u001b[34m(num_runs, num_neighbors, num_rounds_list, dataset, batch_size, val_size, n_trials, prev_best_params)\u001b[39m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m epoch > \u001b[32m0\u001b[39m:\n\u001b[32m    242\u001b[39m         current_lr *= best_params[\u001b[33m'\u001b[39m\u001b[33mlr_decay\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighberhoodmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSNDRPolicyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# learned embeddings (do NOT overwrite originals)\u001b[39;00m\n\u001b[32m    249\u001b[39m learned_x_t, learned_a_t = model.get_params()\n",
      "\u001b[31mTypeError\u001b[39m: train() got multiple values for argument 'criterion'"
     ]
    }
   ],
   "source": [
    "print(\"Value of num_rounds_list:\", num_rounds_list)\n",
    "\n",
    "# Run the optimization\n",
    "df4, best_hyperparams_by_size = trainer_trial(num_runs, num_neighbors, num_rounds_list, train_dataset, batch_size, val_size=10000, n_trials=n_trials_for_optuna, prev_best_params=best_params_to_use)\n",
    "\n",
    "# Print best hyperparameters for each training size\n",
    "print(\"\\n=== BEST HYPERPARAMETERS BY TRAINING SIZE ===\")\n",
    "for train_size, params in best_hyperparams_by_size.items():\n",
    "    print(f\"\\nTraining Size: {train_size}\")\n",
    "    # print(f\"Best Reward: {params['reward']:.6f}\")\n",
    "    print(\"Parameters:\")\n",
    "    for param_name, value in params['params'].items():\n",
    "        print(f\"  {param_name}: {value}\")\n",
    "print(\"===========================\\n\")\n",
    "\n",
    "# Show the performance metrics\n",
    "df4[['policy_rewards', 'ipw', 'reg_dm', 'conv_dm', 'conv_dr', 'conv_sndr', 'action_diff_to_real', 'action_delta', 'context_diff_to_real', 'context_delta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_rewards</th>\n",
       "      <th>ipw</th>\n",
       "      <th>reg_dm</th>\n",
       "      <th>conv_dm</th>\n",
       "      <th>conv_dr</th>\n",
       "      <th>conv_sndr</th>\n",
       "      <th>action_diff_to_real</th>\n",
       "      <th>action_delta</th>\n",
       "      <th>context_diff_to_real</th>\n",
       "      <th>context_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08610747</td>\n",
       "      <td>0.09380742</td>\n",
       "      <td>0.08732337</td>\n",
       "      <td>0.09204356</td>\n",
       "      <td>0.09202231</td>\n",
       "      <td>0.09194136</td>\n",
       "      <td>0.75692870</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.87627132</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.08611565</td>\n",
       "      <td>0.08938694</td>\n",
       "      <td>0.09559770</td>\n",
       "      <td>0.09864954</td>\n",
       "      <td>0.09419736</td>\n",
       "      <td>0.07762452</td>\n",
       "      <td>0.75680212</td>\n",
       "      <td>0.00321359</td>\n",
       "      <td>0.87629079</td>\n",
       "      <td>0.00154774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.08702833</td>\n",
       "      <td>0.09197439</td>\n",
       "      <td>0.09029889</td>\n",
       "      <td>0.10181247</td>\n",
       "      <td>0.09961428</td>\n",
       "      <td>0.09519203</td>\n",
       "      <td>0.77645672</td>\n",
       "      <td>0.18381873</td>\n",
       "      <td>0.88400949</td>\n",
       "      <td>0.07933387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.08611525</td>\n",
       "      <td>0.09211356</td>\n",
       "      <td>0.08769463</td>\n",
       "      <td>0.09043088</td>\n",
       "      <td>0.08906903</td>\n",
       "      <td>0.08397306</td>\n",
       "      <td>0.75688584</td>\n",
       "      <td>0.00360047</td>\n",
       "      <td>0.87628394</td>\n",
       "      <td>0.00160451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.08642838</td>\n",
       "      <td>0.07675940</td>\n",
       "      <td>0.08338645</td>\n",
       "      <td>0.08754185</td>\n",
       "      <td>0.08388183</td>\n",
       "      <td>0.07629422</td>\n",
       "      <td>0.76114452</td>\n",
       "      <td>0.08074157</td>\n",
       "      <td>0.87917341</td>\n",
       "      <td>0.03694905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0.08664700</td>\n",
       "      <td>0.08919219</td>\n",
       "      <td>0.08729591</td>\n",
       "      <td>0.09040812</td>\n",
       "      <td>0.08901549</td>\n",
       "      <td>0.08726893</td>\n",
       "      <td>0.76196226</td>\n",
       "      <td>0.08492833</td>\n",
       "      <td>0.87692124</td>\n",
       "      <td>0.03392471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       policy_rewards        ipw     reg_dm    conv_dm    conv_dr  conv_sndr  \\\n",
       "0          0.08610747 0.09380742 0.08732337 0.09204356 0.09202231 0.09194136   \n",
       "500        0.08611565 0.08938694 0.09559770 0.09864954 0.09419736 0.07762452   \n",
       "1000       0.08702833 0.09197439 0.09029889 0.10181247 0.09961428 0.09519203   \n",
       "2000       0.08611525 0.09211356 0.08769463 0.09043088 0.08906903 0.08397306   \n",
       "10000      0.08642838 0.07675940 0.08338645 0.08754185 0.08388183 0.07629422   \n",
       "20000      0.08664700 0.08919219 0.08729591 0.09040812 0.08901549 0.08726893   \n",
       "\n",
       "       action_diff_to_real  action_delta  context_diff_to_real  context_delta  \n",
       "0               0.75692870    0.00000000            0.87627132     0.00000000  \n",
       "500             0.75680212    0.00321359            0.87629079     0.00154774  \n",
       "1000            0.77645672    0.18381873            0.88400949     0.07933387  \n",
       "2000            0.75688584    0.00360047            0.87628394     0.00160451  \n",
       "10000           0.76114452    0.08074157            0.87917341     0.03694905  \n",
       "20000           0.76196226    0.08492833            0.87692124     0.03392471  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4[['policy_rewards', 'ipw', 'reg_dm', 'conv_dm', 'conv_dr', 'conv_sndr', 'action_diff_to_real', 'action_delta', 'context_diff_to_real', 'context_delta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_rewards</th>\n",
       "      <th>ipw</th>\n",
       "      <th>reg_dm</th>\n",
       "      <th>conv_dm</th>\n",
       "      <th>conv_dr</th>\n",
       "      <th>conv_sndr</th>\n",
       "      <th>action_diff_to_real</th>\n",
       "      <th>action_delta</th>\n",
       "      <th>context_diff_to_real</th>\n",
       "      <th>context_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08610747</td>\n",
       "      <td>0.10697090</td>\n",
       "      <td>0.09051612</td>\n",
       "      <td>0.09112201</td>\n",
       "      <td>0.09452505</td>\n",
       "      <td>0.10672373</td>\n",
       "      <td>0.75692870</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.87627132</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.08705604</td>\n",
       "      <td>0.09221834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08299331</td>\n",
       "      <td>0.08198609</td>\n",
       "      <td>0.07599146</td>\n",
       "      <td>0.79170973</td>\n",
       "      <td>0.24615559</td>\n",
       "      <td>0.88427728</td>\n",
       "      <td>0.08661758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.08939145</td>\n",
       "      <td>0.11301958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08679147</td>\n",
       "      <td>0.09052395</td>\n",
       "      <td>0.10668506</td>\n",
       "      <td>1.01853061</td>\n",
       "      <td>0.76340735</td>\n",
       "      <td>0.91464524</td>\n",
       "      <td>0.19321758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.09251861</td>\n",
       "      <td>0.10603409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09028676</td>\n",
       "      <td>0.15397776</td>\n",
       "      <td>0.10628439</td>\n",
       "      <td>1.73862067</td>\n",
       "      <td>1.70789298</td>\n",
       "      <td>0.99652312</td>\n",
       "      <td>0.34170287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.09268524</td>\n",
       "      <td>0.09704712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09829317</td>\n",
       "      <td>0.09539229</td>\n",
       "      <td>0.09257621</td>\n",
       "      <td>2.18938809</td>\n",
       "      <td>2.22344507</td>\n",
       "      <td>1.03555944</td>\n",
       "      <td>0.40151858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0.09264639</td>\n",
       "      <td>0.09493701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09216787</td>\n",
       "      <td>0.09134166</td>\n",
       "      <td>0.09056984</td>\n",
       "      <td>2.21242505</td>\n",
       "      <td>2.24879912</td>\n",
       "      <td>1.03520993</td>\n",
       "      <td>0.40065441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       policy_rewards        ipw     reg_dm    conv_dm    conv_dr  conv_sndr  \\\n",
       "0          0.08610747 0.10697090 0.09051612 0.09112201 0.09452505 0.10672373   \n",
       "500        0.08705604 0.09221834        NaN 0.08299331 0.08198609 0.07599146   \n",
       "1000       0.08939145 0.11301958        NaN 0.08679147 0.09052395 0.10668506   \n",
       "2000       0.09251861 0.10603409        NaN 0.09028676 0.15397776 0.10628439   \n",
       "10000      0.09268524 0.09704712        NaN 0.09829317 0.09539229 0.09257621   \n",
       "20000      0.09264639 0.09493701        NaN 0.09216787 0.09134166 0.09056984   \n",
       "\n",
       "       action_diff_to_real  action_delta  context_diff_to_real  context_delta  \n",
       "0               0.75692870    0.00000000            0.87627132     0.00000000  \n",
       "500             0.79170973    0.24615559            0.88427728     0.08661758  \n",
       "1000            1.01853061    0.76340735            0.91464524     0.19321758  \n",
       "2000            1.73862067    1.70789298            0.99652312     0.34170287  \n",
       "10000           2.18938809    2.22344507            1.03555944     0.40151858  \n",
       "20000           2.21242505    2.24879912            1.03520993     0.40065441  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the performance metrics\n",
    "df4[['policy_rewards', 'ipw', 'reg_dm', 'conv_dm', 'conv_dr', 'conv_sndr', 'action_diff_to_real', 'action_delta', 'context_diff_to_real', 'context_delta']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
